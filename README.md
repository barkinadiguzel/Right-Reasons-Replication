# ðŸ§  Right-Reasons-Replication â€” Training Models for the Right Reasons

This repository provides a **PyTorch-based research replication** of  
**Right for the Right Reasons: Training Differentiable Models by Constraining their Explanations â€” Ross et al., 2017**.

The project focuses on **faithfully translating the paperâ€™s mathematical formulation and reasoning framework into clean, modular, and inspectable code** â€” without relying on dataset training or benchmarking.

- Enforces **human-defined reasoning constraints** ðŸ§¬  
- Penalizes **spurious correlations via input-gradient regularization** ðŸ©»  
- Forces models to learn **robust, causal decision rules** ðŸ§   

**Paper reference:**  
[Right for the Right Reasons: Training Differentiable Models by Constraining their Explanations â€” Ross et al., 2017](https://arxiv.org/abs/1703.03717) ðŸ“„

---

## ðŸ§¬ Overview â€” Right for the Right Reasons Pipeline

![Right Reasons Overview](images/figmix.jpg)

The core idea:

> Accuracy alone is not enough.  
> A model must be correct **for the correct reasons**.

Instead of optimizing only prediction accuracy, the model is trained under **explanation constraints** that suppress forbidden reasoning paths.

Rather than learning:

$$
x \longrightarrow y
$$

We enforce:

$$
x \longrightarrow y \quad \text{subject to} \quad \nabla_x \hat{y} \;\bot\; \text{forbidden features}
$$

Meaning:  
the model may see all inputs, but is **not allowed to rely on certain features** when forming its decision.

---

## ðŸ”¬ Mathematical Formulation

Let a differentiable model $f_\theta$ produce predictions:

$$
\hat{y} = f_\theta(x)
$$

We define an **annotation matrix**:

$$
A \in \{0,1\}^{N \times D}
$$

Where:
- $N$ = number of samples  
- $D$ = number of features  
- $A_{nd} = 1$ indicates feature $d$ is **forbidden** for sample $n$

We penalize gradients flowing through forbidden features.

The total loss is:

```math
\mathcal{L}(\theta) =
\sum_{n,k} -y_{nk}\log \hat{y}_{nk}
+ \lambda_1 \sum_{n,d} A_{nd}
\left(
\frac{\partial}{\partial x_{nd}}
\sum_k \log \hat{y}_{nk}
\right)^2
+ \lambda_2 \sum_i \theta_i^2
```

Where:
- First term â†’ **Right answers**  
- Second term â†’ **Right reasons** (gradient suppression)  
- Third term â†’ Weight regularization  

This forces the model to find **alternative decision rules** that do not depend on forbidden features.

---

## ðŸ§© What the Model Learns

- To avoid shortcut learning  
- To suppress spurious correlations  
- To ignore confounding signals  
- To discover robust causal features  
- To reason through allowed evidence only  

In effect, we explicitly constrain the model to base its decisions only on causally valid evidence.

---

## ðŸ“¦ Repository Structure

```bash
Right-Reasons-Replication/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ backbone/
â”‚   â”‚   â””â”€â”€ encoder.py              # Input â†’ Feature embedding (MLP / CNN / Transformer)
â”‚   â”‚
â”‚   â”œâ”€â”€ explanation/
â”‚   â”‚   â”œâ”€â”€ gradient_explainer.py   # Input â†’ âˆ‚y/âˆ‚x  (input-gradient computation)
â”‚   â”‚   â”œâ”€â”€ mask_generator.py       # Annotation matrix A generation or loading
â”‚   â”‚   â””â”€â”€ explanation_loss.py     # Right-reason penalty computation
â”‚   â”‚
â”‚   â”œâ”€â”€ model/
â”‚   â”‚   â””â”€â”€ reasoning_model.py      # Feature â†’ Prediction (main classifier)
â”‚   â”‚
â”‚   â”œâ”€â”€ pipeline/
â”‚   â”‚   â””â”€â”€ forward_pipeline.py     # Input â†’ Model â†’ Gradient â†’ Constraint â†’ Loss
â”‚   â”‚
â”‚   â”œâ”€â”€ loss/
â”‚   â”‚   â””â”€â”€ total_loss.py           # Right answer + Right reason + Regularization
â”‚   â”‚
â”‚   â”œâ”€â”€ utils/
â”‚   â”‚   â””â”€â”€ sanity_checks.py        # Verifies forbidden gradients are suppressed
â”‚   â”‚
â”‚   â””â”€â”€ config.py                  # Î»1, Î»2, model size, explanation settings
â”‚
â”œâ”€â”€ images/
â”‚   â””â”€â”€ figmix.jpg                 # Pipeline + geometry visualization
â”‚
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md
```
---


## ðŸ”— Feedback

For questions or feedback, contact: [barkin.adiguzel@gmail.com](mailto:barkin.adiguzel@gmail.com)
